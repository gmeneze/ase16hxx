### Paper Review
Paper: [A Discriminative Model Approach for Accurate Duplicate Bug Report Retreival]  (http://dl.acm.org/citation.cfm?id=1806811)

1. *Reading*
  + 	Chengian Sun, David Lo, Xiaoyin Wang, Jing Jiang, and Siau-Cheng Khoo. 2010. A Discriminative Model Approach for Accurate Duplicate Bug Report Retreival. In Proceedings of the 32nd IEEE/ACM International Conference on Software Engineering - Volume 1.

2. *Keywords*
  1. **Bug Reports**: Any technical issue that occurs in a software application is described in a bug report by the users encountering the bug. The bug reports are stored in an issue database. There can be multiple bug reports for the same technical issue which leads to duplicate bug reports. The aim of the paper is to identify such duplicate reports.
  2. **Automated Triaging**: Whenever a new bug report is issued it should be automatically triaged or detected as a duplicate report which can then later be verified by a triager.
  3. **Pre-processing**: This is the technique in which the data to be classified is subjected to preliminary processing techniques like tokenization (splitting the character stream into token words), stemming (reducing words to their ground form) and stop word removal (removing words with little or no significance) to obtain more accurate classification result. 
  4. **Support Vector Machine**: SVM is a classification or discriminative model technique which is based on set of labeled vectors. This technique builds a hyperplane seperating the set of vectors into positive and negative class. The constructed model then can be utilized to classify an unlabeled vector as positive or negative. 
  5. **Hash Maps**: It is a key-value based data structure. In detection of duplicate reports, all the reports are stored in a hash-map like data structure where the key is the "Master" report that describes one defect and the values are the associated duplicate reports. 

3. *Notes (4 of 19)*
  1. **Motivational Statements**: Bug detection and bug fixing is one of the most important tasks in producing a high quality software product. Bugs are encountered by users working with the software application and the detected bugs are reported by the users via bug reports. Since, there are multiple users using the application, same bugs can be encountered by multiple users and multiple bug reports describing the same issue can be present in the database. Detecting these duplicate bug reports is extremely important as it can eliminate manual intervention to detect duplicate bugs, reduce maintenance effort (if the bug is already fixed) and provide more information about resolving the issue (if the bug is not yet fixed).
  2. **Related Work**: There are various techniques being developed to detect duplicate bug reports using machine learning and natural language processing. One of the most successful techniques in detecting duplicate reports is Natural Language Processing (NLP) technique developed by Runeson et al, in which each report was represented as a vector and cosine, jaccard and dice distance measures were used to calculate similarity between the reports and this technique presented the top-k duplicate reports to the user. Wang et al extended the NLP algorithm mentioned previously by including two dimensions to the features namely local and global features and also used execution traces to detect top-k duplicate reports. A lot of work and research is being performed on bug report data mining and statistical analysis which are extremely effective in detecting duplicate reports.
  3. **Study Instruments**: The authors have tested their algorithm on a subset of bug reports obtained from Eclipse (bugs generated in 2008: 44,652 bug reports), Mozilla(bugs generated from 2002 to June 2007: 47,704 bug reports) and Open Office (bugs generated in 2008: 12,732 bug reports) bug repositories.
  4. **Baseline Results**: The performance of the Discriminative Model (SVM) algorithm is compared against that of the various NLP algorithms proposed by Runeson et al, Wang et al and Zhang et al with respect to recall rate (which is the ratio of detected duplicate bug reports to the total number of duplicate bug reports) on Eclipse, Open Office and Mozilla bug reports. In each of the case the Discriminative model technique outperformed the other NLP based algorithms. On average Discriminative achieved 17–31% relative improvement in OpenOffice dataset, 22–26% in Firefox dataset and 35–43% in Eclipse dataset.

4. *Needs improvement*
  1. The authors of this paper assume that the "Master" reports describe only one distinct bug or defect. The have not considered the possibility of a bug report describing more than one bug and due this oversight it is possible to miss relevant information about a bug.
  2. In this paper duplicate reports are identified only based on the lexical similarity between the reports and not the semantic similarity. If two bug reports refer to the same error but use different terms to describe the issue then this technique does not detect the two reports as duplicates and this affects the accuracy of the system.
  3. The authors have mentioned regarding automatic assignment of optimum weight to each of the 54 extracted features but they have not provided sufficient details regarding weighted features and how weights are assigned automatically.
  4. Popular bug reporting platforms like JIRA and Bugzilla provide the reporter with fields to tag bugs to different topics, versions of the app etc. This information can be used to classify bugs and in some cases textual analysis may not be needed at all because the bug has already been tagged properly. The authors could get better performance using this knowledge.
  5. The technique proposed in the paper detects reports that describe the same technical issue, but it does not detect two or more failures originating from the same source and this detection could be a very useful future improvement.
